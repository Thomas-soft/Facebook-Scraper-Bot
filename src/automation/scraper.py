# Description: Fonctions pour extraire des posts Facebook.
# Version: 1.1

import random
import time
import pyautogui
from selenium.webdriver.common.by import By
from utils.elements import get_element_screen_position
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import os
import csv


def load_scraped_keys(csv_file="posts.csv"):
    """
    Charge depuis le CSV existant les cl√©s (ici : (Auteur, Texte)) des posts d√©j√† scrapp√©s.
    """
    keys = set()
    if os.path.exists(csv_file):
        with open(csv_file, mode="r", newline="", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            for row in reader:
                # On utilise Auteur et Texte pour constituer une cl√© unique
                key = (row.get("Auteur", "").strip(), row.get("Texte", "").strip())
                keys.add(key)
    return keys


def save_posts_to_csv(posts, csv_file="posts.csv"):
    """
    Sauvegarde la liste des posts dans un fichier CSV.
    Les colonnes sont : Auteur, Texte, Images, Videos, Liens externes, Date, Scrapped at.
    """
    fieldnames = ["Auteur", "Texte", "Images", "Videos", "Liens externes", "Date", "Scrapped at"]
    file_exists = os.path.isfile(csv_file)

    with open(csv_file, mode="a", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        if not file_exists:
            writer.writeheader()

        for post in posts:
            row = {}
            row["Auteur"] = post.get("Auteur", "")
            row["Texte"] = post.get("Texte", "")
            # Pour Images
            images = post.get("Images", "")
            if isinstance(images, list):
                row["Images"] = ", ".join(images)
            else:
                row["Images"] = images
            # Pour Videos : conversion de "Vid√©os" vers "Videos"
            videos = post.get("Vid√©os", "")
            if isinstance(videos, list):
                row["Videos"] = ", ".join(videos)
            else:
                row["Videos"] = videos
            # Pour Liens externes
            links = post.get("Liens externes", "")
            if isinstance(links, list):
                row["Liens externes"] = ", ".join(links)
            else:
                row["Liens externes"] = links
            row["Date"] = post.get("Date", "")
            row["Scrapped at"] = time.strftime("%Y-%m-%d %H:%M:%S")
            writer.writerow(row)
    print(f"‚úÖ {len(posts)} post(s) sauvegard√©(s) dans '{csv_file}'.")



def is_element_visible(driver, element, margin=100):
    """V√©rifie si un √©l√©ment est visible √† l'√©cran en tenant compte d'une marge (par d√©faut 100px)."""
    screen_height = driver.execute_script("return window.innerHeight;")
    scroll_position = driver.execute_script("return window.scrollY;")
    element_y = element.location['y']
    return scroll_position <= element_y <= scroll_position + screen_height - margin


def click_see_more_buttons(driver, cursor):
    """Clique sur tous les boutons 'See more' visibles en utilisant le fake cursor.
       Pour ces boutons, on utilise une marge r√©duite afin de cliquer m√™me s'ils se trouvent
       en bas de l'√©cran."""
    try:
        # R√©cup√©rer tous les boutons "See more"
        buttons = driver.find_elements(By.XPATH, "//div[text()='See more']")
        print(f"üîç {len(buttons)} boutons 'See more' d√©tect√©s.")
        for button in buttons:
            # Pour les boutons "See more", on v√©rifie la visibilit√© avec margin=0
            if is_element_visible(driver, button, margin=0):
                try:
                    # R√©cup√©rer la position √† l'√©cran du bouton
                    x, y = get_element_screen_position(driver, button)
                    # D√©placer le curseur vers la position cible
                    cursor.move_random(end=(x + 5, y + 2))
                    # Effectuer un clic avec le fake cursor
                    cursor.click()
                    print("üîò Clic sur 'See more'")
                    time.sleep(random.uniform(0.2, 0.5))  # Pause pour le chargement du contenu √©tendu
                except Exception as e:
                    print(f"‚ö†Ô∏è Erreur lors du clic sur 'See more' : {e}")
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors de la r√©cup√©ration des boutons 'See more' : {e}")


def click_author(driver, post_info, cursor):
    """
    Clique sur l'√©l√©ment auteur d'un post en utilisant le clic du milieu via le fake cursor.
    
    :param driver: instance Selenium du navigateur
    :param post_info: dictionnaire contenant les infos du post (doit contenir "Auteur_element")
    :param cursor: instance de FakeCursor
    """
    try:
        auteur_element = post_info.get("Auteur_element")
        if auteur_element is not None:
            x, y = get_element_screen_position(driver, auteur_element)
            cursor.move_random(end=(x + 5, y + 2))
            cursor.middle_click()
            print("üîò Middle click sur l'auteur :", post_info.get("Auteur"))
        else:
            print("‚ö†Ô∏è Aucune r√©f√©rence √† l'√©l√©ment auteur n'a √©t√© trouv√©e pour ce post.")
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors du clic sur l'auteur : {e}")


def extract_post(driver):
    """Extrait plusieurs post √† partir de la div contenant role='feed'."""
    try:
        print("üîç Recherche de la section 'feed'...")

        # Attendre que la div role="feed" apparaisse
        feed = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.XPATH, "//div[@role='feed']"))
        )

        # R√©cup√©rer **toutes** les div qui suivent imm√©diatement apr√®s cette div "feed"
        post = feed.find_elements(By.XPATH, "./div")

        if not post:
            print("‚ùå Aucun post trouv√©.")
            return []

        nb_post = len(post)
        print(f"üìå {nb_post - 4} post d√©tect√©s. Extraction...")

        extracted_post = []

        for post in post[1:nb_post - 3]:  # Limiter le nombre de post √† extraire
            post_info = {}

            # üîπ Extraction de l'auteur
            try:
                auteur_element = post.find_element(By.XPATH, ".//h2 | .//span/strong")
                post_info["Auteur"] = auteur_element.text
                post_info["Auteur_element"] = auteur_element
            except:
                post_info["Auteur"] = "Inconnu"


            # üîπ Recherche de la div avec data-ad-rendering-role="story_message"
            try:
                message_div = post.find_element(By.XPATH, ".//div[@data-ad-rendering-role='story_message']")
                text_content = message_div.text.strip()
                if text_content:
                    post_info["Texte"] = text_content
                else:
                    post_info["Texte"] = "Aucun texte d√©tect√©"
            except:
                post_info["Texte"] = "Aucun texte d√©tect√©"

            # 4Ô∏è‚É£ Images du post (en filtrant les emojis)
            try:
                images = post.find_elements(By.XPATH, ".//img")

                # Filtrer les images : prendre celles dont la largeur/hauteur est > 100 pixels et qui ne sont pas des emojis
                image_urls = [
                    img.get_attribute("src") for img in images
                    if img.get_attribute("src")
                    and int(img.get_attribute("width") or 0) > 100  # Largeur > 100
                    and int(img.get_attribute("height") or 0) > 100  # Hauteur > 100
                    and "emoji" not in img.get_attribute("src")  # Exclure les emojis
                ]

                post_info["Images"] = image_urls if image_urls else "Aucune image"
            except:
                post_info["Images"] = "Erreur lors de l'extraction"

            # 5Ô∏è‚É£ Vid√©os du post
            try:
                videos = post.find_elements(By.XPATH, ".//video")
                video_urls = [video.get_attribute("src") for video in videos if video.get_attribute("src")]
                post_info["Vid√©os"] = video_urls if video_urls else "Aucune vid√©o"
            except:
                post_info["Vid√©os"] = "Erreur lors de l'extraction"

            # 6Ô∏è‚É£ Liens externes
            try:
                links = post.find_elements(By.XPATH, ".//a")
                external_links = [
                    link.get_attribute("href")
                    for link in links
                    if link.get_attribute("href") and "facebook.com" not in link.get_attribute("href")
                ]
                post_info["Liens externes"] = external_links if external_links else "Aucun lien externe"
            except:
                post_info["Liens externes"] = "Erreur lors de l'extraction"

            # üîπ Extraction de la date
            try:
                post_info["Date"] = post.find_element(By.XPATH, ".//abbr | .//span[contains(@class, 'timestamp')]").text
            except:
                post_info["Date"] = "Non disponible"

            extracted_post.append(post_info)

        # # üìå Affichage des post extraits
        # for i, post in enumerate(extracted_post, 1):
        #     print(f"\n‚úÖ **Post {i} extrait :**")
        #     for key, value in post.items():
        #         print(f"{key}: {value}")

        return extracted_post

    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors de l'extraction des post : {e}")
        return []


def scroll_and_extract(driver, cursor, csv_file="posts.csv", scroll_amount=-2, pause_time=0.1, max_iterations=5):
    """
    D√©file la page, clique sur "See more" et extrait les posts visibles.
    L'extraction s'arr√™te d√®s que 'max_iterations' auteurs uniques (clics sur auteur) ont √©t√© collect√©s.
    """
    posts = []
    seen_keys = set()         # Cl√©s locales pour les posts trait√©s dans cette session
    clicked_authors = set()   # Pour √©viter de cliquer plusieurs fois sur le m√™me auteur dans la session
    first_run = not os.path.exists(csv_file)
    target_authors = max_iterations  # On souhaite exactement 'max_iterations' auteurs uniques
    existing_keys = load_scraped_keys(csv_file)
    duplicate_counter = 0

    while True:
        pyautogui.scroll(scroll_amount)
        time.sleep(pause_time)
        click_see_more_buttons(driver, cursor)
        extracted = extract_post(driver)

        # On r√©cup√®re uniquement les posts dont l'√©l√©ment auteur est visible
        visible_posts = []
        for post in extracted:
            auteur_element = post.get("Auteur_element")
            if auteur_element and is_element_visible(driver, auteur_element):
                visible_posts.append(post)
            else:
                print("Post ignor√© car son auteur n'est pas visible √† l'√©cran.")

        # Traiter chaque post visible
        for post in visible_posts:
            # Normalisation de la cl√© pour √©viter les diff√©rences dues aux espaces superflus
            auteur_text = post.get("Auteur", "").strip()
            texte_text = " ".join(post.get("Texte", "").split())
            key = (auteur_text, texte_text)

            # On ignore ce post si :
            # - La cl√© est d√©j√† pr√©sente (post identique d√©j√† trait√©)
            # - L'auteur a d√©j√† √©t√© cliqu√©
            if key in existing_keys or key in seen_keys or (auteur_text in clicked_authors):
                duplicate_counter += 1
                print("üîÑ Post d√©j√† scrapp√© ou auteur d√©j√† trait√© :", key)
            else:
                duplicate_counter = 0
                seen_keys.add(key)
                posts.append(post)
                existing_keys.add(key)
                print("üÜï Nouveau post ajout√© :", key)

                clic_num = len(clicked_authors) + 1
                print(f"üîò Clic num√©ro {clic_num} sur l'auteur : {auteur_text}")
                click_author(driver, post, cursor)
                clicked_authors.add(auteur_text)

            # On s'arr√™te d√®s que le nombre d'auteurs uniques cliqu√©s atteint le seuil cible
            if len(clicked_authors) >= target_authors:
                print(f"‚úÖ Nombre d'auteurs cibles atteint ({target_authors}).")
                return posts

        # En mode non-premier lancement, on arr√™te si 3 posts cons√©cutifs d√©j√† scrap√©s sont rencontr√©s
        if not first_run and duplicate_counter >= 3:
            print("‚ö†Ô∏è 3 posts cons√©cutifs d√©j√† scrap√©s rencontr√©s. Arr√™t de l'extraction.")
            return posts

    print(f"üìù Total posts extraits et trait√©s : {len(posts)}")
    print("üîö Fin de l'extraction.")
    print("R√©capitulatif des posts extraits :")
    for i, post in enumerate(posts, 1):
        print(f"\n‚úÖ **Post {i} extrait :**")
        for key, value in post.items():
            print(f"{key}: {value}")
    return posts


def set_filter_recent(driver, cursor):
    """D√©finit le filtre des posts √† 'Les plus r√©cents'."""
    # Clic sur le bouton 'Les plus r√©cents'
    cursor.move_random(
        None,
        (
            random.randint(10, pyautogui.size()[0] - 10),
            random.randint(200, 250)
        )
    )
    try:
        filter_button = driver.find_element(By.XPATH, "//span[text()='Most relevant']")
        if filter_button is None:
            print("‚ö†Ô∏è 'Most relevant' non trouv√©.")
            return
        else:
            print("‚úÖ 'Most relevant' trouv√©.")
        if is_element_visible(driver, filter_button):
            x, y = get_element_screen_position(driver, filter_button)
            cursor.move_random(None, (x + 5, y + 2))
            cursor.click()
            print("üîò Clic sur 'Most relevant'")
        else:
            while not is_element_visible(driver, filter_button):
                pyautogui.scroll(-1)
                time.sleep(random.uniform(0.01, 0.1))
            x, y = get_element_screen_position(driver, filter_button)
            cursor.move_random(None, (x + 5, y + 2))
            cursor.click()
        recent_button = driver.find_element(By.XPATH, "//span[text()='Recent activity']")
        if recent_button is None:
            print("‚ö†Ô∏è 'Recent activity' non trouv√©.")
            return
        else:
            print("‚úÖ 'Recent activity' trouv√©.")
        if is_element_visible(driver, recent_button):
            x, y = get_element_screen_position(driver, recent_button)
            cursor.move_random(None, (x + 5, y + 2))
            cursor.click()
            print("üîò Clic sur 'Recent activity'")
        else:
            while not is_element_visible(driver, recent_button):
                pyautogui.scroll(-1)
                time.sleep(random.uniform(0.01, 0.1))
            x, y = get_element_screen_position(driver, recent_button)
            cursor.move_random(None, (x + 5, y + 2))
            cursor.click()
        time.sleep(0.6)
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors du clic sur 'Most relevant' : {e}")
